# -*- coding: utf-8 -*-
"""Kopie von wdnn_call_2.0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PspPQJSosZN1N8N3QxQwNsLvELYyj3w8

# Load Data
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import tensorflow as tf
from tensorflow import keras
import pandas as pd
put=pd.read_csv('/content/drive/MyDrive/Thesis/Data/input/put.csv')

put.describe().apply(lambda s: s.apply('{0:.5f}'.format))

"""# Split and normalize data"""

train = put[(put['date'] > '2015-12-31') & (put['date'] < '2020-09-01')]
valid = put[(put['date'] >= '2020-09-01') & (put['date'] < '2020-11-01')]
test = put[(put['date'] >= '2020-11-01')]

#shuffle data
train = train.sample(frac=1)
valid = valid.sample(frac=1)

X_train=train[['K', 'S', 'sigma', 'T', 'riskfree', 'D']]
X_test=test[['K', 'S', 'sigma', 'T', 'riskfree', 'D']]
X_valid = valid[['K', 'S', 'sigma', 'T', 'riskfree', 'D']]

y_train = train["bidaskmean"]
y_test = test["bidaskmean"]
y_valid = valid  ["bidaskmean"]

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler() 
X_train = scaler.fit_transform(X_train) 
X_valid = scaler.transform(X_valid) 
X_test = scaler.transform(X_test)

train.head()

"""# Train and evaluate model"""

input_ = keras.layers.Input(shape=[6])
hidden1 = keras.layers.Dense(400, activation="relu", kernel_constraint=keras.constraints.max_norm(1.0))(input_)
hidden2 = keras.layers.Dense(400, activation="relu", kernel_constraint=keras.constraints.max_norm(1.0))(hidden1)
hidden3 = keras.layers.Dense(400, activation="relu", kernel_constraint=keras.constraints.max_norm(1.0))(hidden2)
concat = keras.layers.Concatenate()([input_, hidden3])
output = keras.layers.Dense(1, activation="relu")(concat)
model = keras.Model(inputs=[input_], outputs=[output])

checkpoint_cb = keras.callbacks.ModelCheckpoint("wdnn_put_2.0.h5", save_best_only=True)
early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
tensorboard_cb = keras.callbacks.TensorBoard('/content/drive/MyDrive/Thesis/Data/logs')
#lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=10)

model.compile(loss="mse", optimizer=keras.optimizers.Adam(lr=0.01))
history = model.fit(X_train, y_train, epochs=200, batch_size=10000, validation_data=(X_valid, y_valid), 
                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])
model = keras.models.load_model("wdnn_put_2.0.h5") 

y_pred_valid = model.predict(X_valid)

#valid wdnn
from sklearn.metrics import mean_squared_error
print(mean_squared_error(y_valid, y_pred_valid))
from sklearn.metrics import mean_absolute_error
print(mean_absolute_error(y_valid, y_pred_valid))
from sklearn.metrics import median_absolute_error
print(median_absolute_error(y_valid, y_pred_valid))

#valid bs
from sklearn.metrics import mean_squared_error
print(mean_squared_error(y_valid, valid["bs"]))
from sklearn.metrics import mean_absolute_error
print(mean_absolute_error(y_valid, valid["bs"]))
from sklearn.metrics import median_absolute_error
print(median_absolute_error(y_valid, valid["bs"]))

y_pred_train = model.predict(X_train)

#train wdnn
from sklearn.metrics import mean_squared_error
print(mean_squared_error(y_train, y_pred_train))
from sklearn.metrics import mean_absolute_error
print(mean_absolute_error(y_train, y_pred_train))
from sklearn.metrics import median_absolute_error
print(median_absolute_error(y_train, y_pred_train))

#train bs
from sklearn.metrics import mean_squared_error
print(mean_squared_error(y_train, train["bs"]))
from sklearn.metrics import mean_absolute_error
print(mean_absolute_error(y_train, train["bs"]))
from sklearn.metrics import median_absolute_error
print(median_absolute_error(y_train, train["bs"]))

y_pred = model.predict(X_test)

#test wdnn
from sklearn.metrics import mean_squared_error
print(mean_squared_error(y_test, y_pred))
from sklearn.metrics import mean_absolute_error
print(mean_absolute_error(y_test, y_pred))
from sklearn.metrics import median_absolute_error
print(median_absolute_error(y_test, y_pred))
#from sklearn.metrics import mean_absolute_percentage_error
#print(mean_absolute_percentage_error(y_pred, y_test))

#test bs
from sklearn.metrics import mean_squared_error
print(mean_squared_error(y_test, test["bs"]))
from sklearn.metrics import mean_absolute_error
print(mean_absolute_error(y_test, test["bs"]))
from sklearn.metrics import median_absolute_error
print(median_absolute_error(y_test, test["bs"]))
#from sklearn.metrics import mean_absolute_percentage_error
#print(mean_absolute_percentage_error(y_pred, y_test))

test["wdnn"] = y_pred
test.describe()

model.save("/content/drive/MyDrive/Thesis/Data/models/wdnn_put_2.0.h5")
test.to_csv('/content/drive/MyDrive/Thesis/Data/output/test_put_2.0.csv')

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard 
# %tensorboard --logdir=/content/drive/MyDrive/Thesis/Data/logs --port=6006